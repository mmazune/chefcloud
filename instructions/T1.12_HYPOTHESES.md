# T1.12 — Hypotheses for E2E Timeout Fix

**Date:** 2025-12-29  
**Context:** 12 test files timeout at exactly 120s each; all use `cleanup(app)` which calls `enableShutdownHooks()` in afterAll

---

## H1: enableShutdownHooks() called AFTER app.init() (90% confidence)

### Evidence
- All 12 timed-out files call `await app.init()` in beforeAll
- NONE of them call `app.enableShutdownHooks()` before init
- cleanup.ts calls `enableShutdownHooks()` in afterAll, but by then:
  - App is already running
  - Prisma/Redis/BullMQ connections already open
  - `onModuleInit` hooks already fired without shutdown hooks registered
- NestJS docs: "enableShutdownHooks() must be called BEFORE app.init() for lifecycle hooks to work"

### Pattern Analysis
```typescript
// CURRENT BROKEN PATTERN (all 12 timeout files):
beforeAll(async () => {
  const moduleFixture = await Test.createTestingModule({ imports: [AppModule] }).compile();
  app = moduleFixture.createNestApplication();
  await app.init();  // ❌ Shutdown hooks not enabled yet!
});

afterAll(async () => {
  await cleanup(app);  // Calls enableShutdownHooks() here - TOO LATE
});
```

### Smallest Experiment
1. Patch test/a3-pos.e2e-spec.ts to add:
   ```typescript
   app = moduleFixture.createNestApplication();
   app.enableShutdownHooks();  // ADD THIS LINE
   await app.init();
   ```
2. Run: `timeout 3m pnpm test:e2e -- --runTestsByPath test/a3-pos.e2e-spec.ts --runInBand`
3. Expected: Completes in <10s instead of timing out at 120s

### Confirmation Method
- If test completes cleanly: H1 is PRIMARY CAUSE
- If still times out: H1 contributes but not sole cause

---

## H2: The 12 files bypass e2e-bootstrap.ts and construct apps manually (70% confidence)

### Evidence
- e2e-bootstrap.ts only provides `createE2ETestingModule()` and `createE2ETestingModuleBuilder()`
- These helpers only wrap `Test.createTestingModule()` - they don't create the app
- Each test file manually calls `moduleFixture.createNestApplication()` and `app.init()`
- Pattern search confirms:
  - 20+ files import `createE2ETestingModule`
  - But ALL still manually create app and call init
  - No helper exists for "create and init app with proper shutdown hooks"

### Current Helper Limitation
```typescript
// e2e-bootstrap.ts only does this:
export async function createE2ETestingModule(metadata) {
  const moduleBuilder = Test.createTestingModule(metadata);
  return moduleBuilder.compile();
}
// ❌ Does NOT create app or call enableShutdownHooks()
```

### Smallest Experiment
1. Check if ANY timed-out files use e2e-bootstrap:
   ```bash
   grep -l "createE2ETestingModule" test/a3-pos.e2e-spec.ts test/auth.e2e-spec.ts test/e22-franchise.e2e-spec.ts
   ```
2. Expected: NONE of the 12 timeout files use the helper (they all use raw Test.createTestingModule)

### Confirmation Method
- If timeout files DON'T use helper: Add app creation to helper and migrate tests
- If they DO use helper: Helper needs to create app with shutdown hooks enabled

---

## H3: cleanup(app) not reached due to awaiting never-resolving handle during module destroy (50% confidence)

### Evidence
- Jest message from previous runs: "did not exit one second after completion"
- Suggests test passes but process hangs
- Common culprits in AppModule:
  - Prisma: $disconnect() may wait for pending queries
  - Redis: quit() may wait for pending commands
  - BullMQ: Workers don't stop automatically
  - SSE: Open event streams block shutdown
  - Timers: setInterval() without clearInterval()

### Diagnostic Pattern
All timeout files use full AppModule which includes:
- PrismaModule (global, connection pool)
- RedisModule (global, pub/sub + cache)
- BullMQModule (queue workers)
- ThrottlerModule (rate limiting storage)
- ScheduleModule (cron jobs)

Any of these can have open handles that block app.close()

### Smallest Experiment
1. Run one timeout file with Jest's handle detection:
   ```bash
   timeout 3m pnpm test:e2e -- --runTestsByPath test/a3-pos.e2e-spec.ts --runInBand --detectOpenHandles
   ```
2. Check output for:
   - "Jest has detected the following open handles"
   - Lists of Timers, Sockets, or Promises
3. Expected: Will show specific module/service keeping process alive

### Confirmation Method
- If handles listed: Those are the specific services to fix (add explicit cleanup)
- If no handles: Not the root cause (H1 is more likely)

---

## H4: One module in AppModule starts long-lived worker in onModuleInit and never stops (40% confidence)

### Evidence
- BullMQ workers run in background
- SSE keeps connections open
- ScheduleModule can start cron jobs
- Any of these can prevent graceful shutdown if:
  - They don't implement onModuleDestroy
  - They don't listen to SIGTERM
  - They use detached processes

### Likely Suspects
1. **BullMQ Workers**: Queue.process() runs continuously
2. **SSE Service**: Long-polling connections
3. **Scheduler**: @Cron() decorators may not stop
4. **Redis Pub/Sub**: Subscriptions keep connection alive

### Smallest Experiment
1. Check if BullMQ/Scheduler modules implement onModuleDestroy:
   ```bash
   grep -r "onModuleDestroy" src/modules/billing src/modules/kpis src/modules/notifications
   ```
2. Run timeout test with strace to see blocking syscalls:
   ```bash
   timeout 3m strace -e epoll_wait,poll,select pnpm test:e2e -- --runTestsByPath test/a3-pos.e2e-spec.ts --runInBand 2>&1 | tail -100
   ```
3. Expected: Will show process blocking on socket read/write

### Confirmation Method
- If workers found without cleanup: Add onModuleDestroy to those modules
- If no workers: H4 is not the cause

---

## HYPOTHESIS RANKING

| Hypothesis | Confidence | Ease of Fix | Priority |
|------------|-----------|-------------|----------|
| **H1: enableShutdownHooks after init** | 90% | **EASY** (1 line per file or systemic helper) | **1** |
| **H2: Files bypass shared bootstrap** | 70% | MEDIUM (create proper helper + migrate) | **2** |
| **H3: Open handles block shutdown** | 50% | HARD (need to identify and close each) | **3** |
| **H4: Long-lived workers** | 40% | HARD (module-level refactor) | **4** |

---

## RECOMMENDED APPROACH

### Phase 1: Test H1 (Quick Win)
1. Apply enableShutdownHooks() fix to ONE timeout file (a3-pos)
2. If it works: Apply systemic fix via enhanced helper
3. If it doesn't: Move to H3 (detect open handles)

### Phase 2: Systemic Fix (If H1 Confirmed)
1. Enhance e2e-bootstrap.ts to provide:
   ```typescript
   export async function createE2EApp(metadata: ModuleMetadata) {
     const moduleRef = await Test.createTestingModule(metadata).compile();
     const app = moduleRef.createNestApplication();
     app.enableShutdownHooks();  // CRITICAL: Before init
     await app.init();
     return app;
   }
   ```
2. Migrate all 12 timeout files to use this helper
3. Remove enableShutdownHooks() call from cleanup.ts (no longer needed)

### Phase 3: Handle Detection (If H1 Partial)
1. For any remaining timeouts, use --detectOpenHandles
2. Identify specific services (Prisma/Redis/BullMQ)
3. Add explicit cleanup in those modules' onModuleDestroy

---

**END OF HYPOTHESES**
